# ãƒ•ã‚¡ã‚¤ãƒ«å: evaluation_utils.py

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
import wandb

from diffusers import DDPMScheduler, DPMSolverMultistepScheduler, EulerDiscreteScheduler
from torchmetrics.image import StructuralSimilarityIndexMeasure
from skimage.metrics import peak_signal_noise_ratio as psnr
from torch.cuda.amp import autocast

from inferers import SlidingWindowInferer
from models import DistributedUNet


class EMA:
    """
    ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æŒ‡æ•°ç§»å‹•å¹³å‡ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self, model, decay):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}

        self.register()

    def register(self):
        """ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒ‰ã‚¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦ç™»éŒ²ã™ã‚‹ã€‚"""
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.shadow[name] = param.data.clone()

    def update(self):
        """ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä½¿ã£ã¦ã‚·ãƒ£ãƒ‰ã‚¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€‚"""
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.shadow
                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]
                self.shadow[name] = new_average.clone()

    def apply_shadow(self):
        """æ¨è«–ã®ãŸã‚ã«ã€ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ã‚·ãƒ£ãƒ‰ã‚¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ç½®ãæ›ãˆã‚‹ã€‚"""
        self.backup = {}
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                self.backup[name] = param.data
                param.data = self.shadow[name]

    def restore(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦ãŠã„ãŸå…ƒã®ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã«æˆ»ã™ã€‚"""
        for name, param in self.model.named_parameters():
            if param.requires_grad:
                assert name in self.backup
                param.data = self.backup[name]
        self.backup = {}

    def state_dict(self):
        return self.shadow

    def load_state_dict(self, state_dict):
        self.shadow = state_dict

def calculate_mae(image_true, image_test):
    """å¹³å‡çµ¶å¯¾èª¤å·® (MAE) ã‚’è¨ˆç®—ã™ã‚‹"""
    return np.mean(np.abs(image_true - image_test))


def create_evaluation_report(generated_hu_np, ground_truth_hu_np, ssim_score, psnr_score, mae_score, title_prefix):
    """
    ç”Ÿæˆã•ã‚ŒãŸCTã¨æ­£è§£CTã‚’æ¯”è¼ƒã™ã‚‹è©³ç´°ãªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆç”»åƒï¼‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

    Args:
        generated_hu_np (np.ndarray): ç”Ÿæˆã•ã‚ŒãŸCTãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆHUå€¤ï¼‰
        ground_truth_hu_np (np.ndarray): æ­£è§£ã®CTãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆHUå€¤ï¼‰
        ssim_score (float): SSIMã‚¹ã‚³ã‚¢
        psnr_score (float): PSNRã‚¹ã‚³ã‚¢
        mae_score (float): MAEã‚¹ã‚³ã‚¢
        title_prefix (str): å›³ã®ã‚¿ã‚¤ãƒˆãƒ«ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹

    Returns:
        matplotlib.figure.Figure: ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®Figureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®— (ç©ºæ°—ä»¥å¤–)
    non_air_voxels_gen = generated_hu_np[generated_hu_np > -1000]
    stats_gen = {
        'mean': np.mean(non_air_voxels_gen), 'std': np.std(non_air_voxels_gen),
        'min': np.min(non_air_voxels_gen), 'max': np.max(non_air_voxels_gen)
    } if non_air_voxels_gen.size > 0 else {}

    non_air_voxels_gt = ground_truth_hu_np[ground_truth_hu_np > -1000]
    stats_gt = {
        'mean': np.mean(non_air_voxels_gt), 'std': np.std(non_air_voxels_gt),
        'min': np.min(non_air_voxels_gt), 'max': np.max(non_air_voxels_gt)
    } if non_air_voxels_gt.size > 0 else {}

    fig = plt.figure(figsize=(20, 14), facecolor='black')
    gs = plt.GridSpec(3, 4, figure=fig)
    
    z, y, x = ground_truth_hu_np.shape
    slice_ax, slice_cor, slice_sag = z // 2, y // 2, x // 2
    vmin, vmax = -1024, 300 # è¡¨ç¤ºã‚¦ã‚£ãƒ³ãƒ‰ã‚¦

    views = {
        'Axial': (ground_truth_hu_np[slice_ax, :, :], generated_hu_np[slice_ax, :, :], gs[0, 0], gs[0, 1]),
        'Coronal': (np.flipud(ground_truth_hu_np[:, slice_cor, :]), np.flipud(generated_hu_np[:, slice_cor, :]), gs[1, 0], gs[1, 1]),
        'Sagittal': (np.fliplr(np.flipud(ground_truth_hu_np[:, :, slice_sag])), np.fliplr(np.flipud(generated_hu_np[:, :, slice_sag])), gs[2, 0], gs[2, 1])
    }

    for title, (gt_img, gen_img, gs_gt, gs_gen) in views.items():
        ax_gt = fig.add_subplot(gs_gt)
        ax_gt.imshow(gt_img, cmap='gray', vmin=vmin, vmax=vmax)
        ax_gt.set_title(f'Ground Truth {title}', color='cyan')
        ax_gt.axis('off')

        ax_gen = fig.add_subplot(gs_gen)
        ax_gen.imshow(gen_img, cmap='gray', vmin=vmin, vmax=vmax)
        ax_gen.set_title(f'Generated {title}', color='magenta')
        ax_gen.axis('off')

    # 8. çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®— (ç©ºæ°—ä»¥å¤–)
    print("  â³ Calculating statistics (excluding air)...")
    non_air_voxels_gen = generated_hu_np[generated_hu_np > -1000]
    stats_gen = {
        'mean': np.mean(non_air_voxels_gen), 'std': np.std(non_air_voxels_gen),
        'min': np.min(non_air_voxels_gen), 'max': np.max(non_air_voxels_gen)
    } if non_air_voxels_gen.size > 0 else {}

    non_air_voxels_gt = ground_truth_hu_np[ground_truth_hu_np > -1000]
    stats_gt = {
        'mean': np.mean(non_air_voxels_gt), 'std': np.std(non_air_voxels_gt),
        'min': np.min(non_air_voxels_gt), 'max': np.max(non_air_voxels_gt)
    } if non_air_voxels_gt.size > 0 else {}

    # --- â˜… å¤‰æ›´ç‚¹: ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®Xè»¸ã‚’çµ±ä¸€ ---
    # ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰æœ€å°å€¤ã¨æœ€å¤§å€¤ã‚’è¨ˆç®—ã—ã¦ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®æç”»ç¯„å›²ã‚’æ±ºå®šã™ã‚‹
    hist_min = min(stats_gt.get('min', 0), stats_gen.get('min', 0))
    hist_max = max(stats_gt.get('max', 0), stats_gen.get('max', 0))
    # å®‰å…¨ãƒãƒ¼ã‚¸ãƒ³ã‚’è¿½åŠ 
    hist_range = (hist_min - 50, hist_max + 50)

    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ  (çµ±ä¸€ã—ãŸç¯„å›²ã§æç”»)
    ax_hist_gt = fig.add_subplot(gs[0, 2]); ax_hist_gen = fig.add_subplot(gs[0, 3])
    if stats_gt: ax_hist_gt.hist(non_air_voxels_gt.flatten(), bins=100, color='deepskyblue', range=hist_range)
    ax_hist_gt.set_title("Ground Truth - HU Histogram", color='cyan'); ax_hist_gt.set_facecolor('darkgray'); ax_hist_gt.tick_params(colors='white')
    if stats_gen: ax_hist_gen.hist(non_air_voxels_gen.flatten(), bins=100, color='orchid', range=hist_range)
    ax_hist_gen.set_title("Generated - HU Histogram", color='magenta'); ax_hist_gen.set_facecolor('darkgray'); ax_hist_gen.tick_params(colors='white')

    # çµ±è¨ˆæƒ…å ±ã¨ã‚¹ã‚³ã‚¢
    ax_text = fig.add_subplot(gs[1:, 2:]); ax_text.axis('off')
    report_text = (
        f"--- Quality Metrics ---\n"
        f"  SSIM: {ssim_score:.4f}\n"
        f"  PSNR: {psnr_score:.2f} dB\n"
        f"  MAE:  {mae_score:.2f} HU\n\n"
        f"--- Statistics (HU, > -1000) ---\n"
        f"  [Ground Truth]\n"
        f"    Mean / Std: {stats_gt.get('mean', 0):.2f} / {stats_gt.get('std', 0):.2f}\n"
        f"    Min / Max:  {stats_gt.get('min', 0):.0f} / {stats_gt.get('max', 0):.0f}\n\n"
        f"  [Generated]\n"
        f"    Mean / Std: {stats_gen.get('mean', 0):.2f} / {stats_gen.get('std', 0):.2f}\n"
        f"    Min / Max:  {stats_gen.get('min', 0):.0f} / {stats_gen.get('max', 0):.0f}\n"
    )
    ax_text.text(0.05, 0.7, report_text, color='white', fontfamily='monospace', fontsize=14, va='top')

    fig.suptitle(title_prefix, color='white', fontsize=20)
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    return fig


def generate_and_evaluate(device, params, scheduler_name, ct_full, drr1, drr2, pos_3d, best_epoch, trial_number, save_dir, model_for_inference):
    print(f"--- Starting Generation & Evaluation on device: {device} ---")

    vis_dir = Path(save_dir) / "evaluation" # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåã‚’å¤‰æ›´
    vis_dir.mkdir(exist_ok=True, parents=True)

    # 1. ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
    is_distributed = isinstance(model_for_inference, DistributedUNet)
    if is_distributed:
        model_for_inference.eval()
        print("  [Visualization] Using provided DistributedUNet model.")
    else: # single GPU mode (visualization.pyç”¨)
        model_for_inference['unet'].eval()
        model_for_inference['conditioning_encoder'].eval()
        print("  [Visualization] Using provided single-GPU models.")

    # EMAãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’é©ç”¨
    if is_distributed and hasattr(model_for_inference, 'ema'):
        model_for_inference.ema.apply_shadow()
    elif not is_distributed and 'ema' in model_for_inference:
        model_for_inference['ema'].apply_shadow()

    
    # 3. ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’é¸æŠ
    if scheduler_name == "dpm_solver":
        scheduler = DPMSolverMultistepScheduler(num_train_timesteps=1000)
    elif scheduler_name == "euler":
        scheduler = EulerDiscreteScheduler(num_train_timesteps=1000)
    else: # ddpm
        scheduler = DDPMScheduler(num_train_timesteps=1000)

    # 4. æ¨è«–ã®æº–å‚™
    ct_full, drr1, drr2 = ct_full.to(device), drr1.to(device), drr2.to(device)

    # â˜… å¤‰æ›´ç‚¹: ãƒ•ãƒ«ãƒœãƒªãƒ¥ãƒ¼ãƒ ç”¨ã®æ­£ã—ã„ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”Ÿæˆã™ã‚‹
    # generate_and_evaluateã¯ãƒ•ãƒ«ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’å¯¾è±¡ã¨ã™ã‚‹ãŸã‚ã€ãƒœãƒªãƒ¥ãƒ¼ãƒ å…¨ä½“ã®åº§æ¨™ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    # SlidingWindowInfererã¯ã€ã“ã®ãƒ•ãƒ«ãƒœãƒªãƒ¥ãƒ¼ãƒ ç”¨ã®åº§æ¨™ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰ã€å„ãƒ‘ãƒƒãƒã«å¯¾å¿œã™ã‚‹éƒ¨åˆ†ã‚’åˆ‡ã‚Šå‡ºã—ã¦ä½¿ç”¨ã™ã‚‹ã€‚
    _, _, d, h, w = ct_full.shape
    pos_d = torch.linspace(-1.0, 1.0, d)
    pos_h = torch.linspace(-1.0, 1.0, h)
    pos_w = torch.linspace(-1.0, 1.0, w)
    # (3, N) ã®å½¢çŠ¶ã§ã‚¹ã‚¿ãƒƒã‚¯ã—ã€ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
    pos_3d = torch.stack([pos_d, pos_h, pos_w], dim=0).to(device)
    
    # â˜… å¤‰æ›´ç‚¹: SlidingWindowInfererã‚’ä½¿ç”¨ã—ã¦ãƒ•ãƒ«ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’æ¨è«–
    patch_size = (params['patch_size'], params['patch_size'], params['patch_size'])
    inferer = SlidingWindowInferer(
        roi_size=patch_size, 
        sw_batch_size=1, 
        overlap=params.get('patch_overlap', 0.5), # configã‹ã‚‰overlapã‚’å–å¾—
        mode=params.get('blend_mode', 'cosine')) # configã‹ã‚‰blend_modeã‚’å–å¾—

    # 5. æ¨è«–ã‚’å®Ÿè¡Œ
    with torch.no_grad(), autocast(enabled=False): # æ¨è«–æ™‚ã¯æ··åˆç²¾åº¦ã‚’ã‚ªãƒ•
        initial_noise = torch.randn_like(ct_full)
        scheduler.set_timesteps(num_inference_steps=50)
        image = initial_noise

        for t in tqdm(scheduler.timesteps, desc=f"ğŸ–¼ï¸ Visualizing Trial {trial_number} (Full Volume)"):
            timesteps_tensor = torch.tensor((t,), device=image.device).long().repeat(image.shape[0])
            
            if is_distributed:
                # åˆ†æ•£ãƒ¢ãƒ‡ãƒ«ç”¨ã®æ¨è«–é–¢æ•°
                context = model_for_inference.conditioning_encoder(drr1, drr2) # contextã¯äº‹å‰ã«è¨ˆç®—
                model_func = lambda x, **kwargs: model_for_inference(x=x, timesteps=timesteps_tensor, context=context, **kwargs)
                model_output = inferer(inputs=image, network=model_func, pos_3d=pos_3d)
            else:
                # å˜ä¸€GPUãƒ¢ãƒ‡ãƒ«ç”¨ã®æ¨è«–é–¢æ•°
                context = model_for_inference['conditioning_encoder'](drr1, drr2) # contextã¯äº‹å‰ã«è¨ˆç®—
                model_func = lambda x, **kwargs: model_for_inference['unet'](x, timesteps=timesteps_tensor, context=context, **kwargs)
                model_output = inferer(inputs=image, network=model_func, pos_3d=pos_3d)
            
            image = scheduler.step(model_output, t, image).prev_sample

    # EMAãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å…ƒã«æˆ»ã™
    if is_distributed and hasattr(model_for_inference, 'ema'):
        model_for_inference.ema.restore()
    elif not is_distributed and 'ema' in model_for_inference:
        model_for_inference['ema'].restore()

    # 6. çµæœã‚’HUå€¤ã«é€†æ­£è¦åŒ–
    # 6a. æ¨è«–çµæœã‚’æ­£è¦åŒ–ç¯„å›² [0, 1] ã«ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
    #     æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã¯ç¯„å›²å¤–ã®å€¤ã‚’å–ã‚Šã†ã‚‹ãŸã‚ã€ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ãŒä¸å¯æ¬ 
    image = torch.clamp(image, 0, 1)
    ct_full = torch.clamp(ct_full, 0, 1)

    print("  De-normalizing images to HU range...")
    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®HUç¯„å›²
    min_hu = -1024
    max_hu = 1500

    # 6b. [0, 1] ã®ç¯„å›²ã‹ã‚‰ [min_hu, max_hu] ã®ç¯„å›²ã«ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
    generated_hu_np = image.squeeze().cpu().numpy() * (max_hu - min_hu) + min_hu
    ground_truth_hu_np = ct_full.squeeze().cpu().numpy() * (max_hu - min_hu) + min_hu

    # ç”Ÿæˆã•ã‚ŒãŸCTãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚’NumPyé…åˆ—ã¨ã—ã¦ä¿å­˜
    save_npy_path = vis_dir / f"generated_ct_trial_{trial_number}_epoch_{best_epoch}_HU.npy"
    np.save(save_npy_path, generated_hu_np)
    print(f"  ğŸ’¾ Generated CT volume saved as numpy array: {save_npy_path}")

    # 7. å“è³ªè©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—
    print("  ğŸ“Š Calculating quality metrics...")
    data_range = max_hu - min_hu # è©•ä¾¡ç¯„å›²ã‚’å›ºå®š
    ssim_score = StructuralSimilarityIndexMeasure(data_range=data_range)(torch.from_numpy(generated_hu_np).unsqueeze(0).unsqueeze(0), torch.from_numpy(ground_truth_hu_np).unsqueeze(0).unsqueeze(0)).item()
    psnr_score = psnr(ground_truth_hu_np, generated_hu_np, data_range=data_range)
    mae_score = calculate_mae(ground_truth_hu_np, generated_hu_np)
    print(f"  -> SSIM={ssim_score:.4f}, PSNR={psnr_score:.2f} dB, MAE={mae_score:.2f} HU")

    # 9. è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    print("  ğŸ–¼ï¸ Creating evaluation report...")
    fig = create_evaluation_report(
        generated_hu_np=generated_hu_np,
        ground_truth_hu_np=ground_truth_hu_np,
        ssim_score=ssim_score,
        psnr_score=psnr_score,
        mae_score=mae_score,
        title_prefix=f'Evaluation Report for Trial {trial_number} (Epoch {best_epoch})'
    )
    
    save_path = vis_dir / f"evaluation_report_trial_{trial_number}_epoch_{best_epoch}.png"
    plt.savefig(save_path, facecolor='black')
    wandb.log({"Evaluation_Report": wandb.Image(fig)}, step=wandb.run.step)
    plt.close(fig)
    print(f"  âœ… Evaluation report saved to: {save_path}")